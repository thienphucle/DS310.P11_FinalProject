{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48UH6zEyaSc8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVdb62fRyhTn"
   },
   "outputs": [],
   "source": [
    "def load_vocab_dict(path: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Reads a vocabulary list from a file and creates a dictionary mapping each word to its index.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the vocabulary list.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: A tuple containing the list of vocabulary words and a dictionary\n",
    "                                          mapping each word to its index.\n",
    "    \"\"\"\n",
    "    vocab = open(path).read().strip().split('\\n')\n",
    "    return vocab, {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkJ7fQifz532"
   },
   "outputs": [],
   "source": [
    "def read_corpus(path: str) -> List[str]:\n",
    "    \"\"\"Reads the corpus from a file, excluding the last empty entry if the file ends with a newline.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the corpus.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of strings, each representing a line from the file.\n",
    "    \"\"\"\n",
    "    return open(path).read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cgReXf9FIl2"
   },
   "outputs": [],
   "source": [
    "def counting(corpus: List[str], V: List[str], V_C: List[str], V_set: Dict[str, int], V_C_set: Dict[str, int], w: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a co-occurrence (counting) matrix from the given corpus, considering specified vocabularies and a window size.\n",
    "\n",
    "    Args:\n",
    "        corpus (List[str]): The corpus as a list of sentences.\n",
    "        V (List[str]): The list of vocabulary words.\n",
    "        V_C (List[str]): The list of context vocabulary words.\n",
    "        V_set (Dict[str, int]): A dictionary mapping vocabulary words to their indices.\n",
    "        V_C_set (Dict[str, int]): A dictionary mapping context vocabulary words to their indices.\n",
    "        w (int): The window size for context.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array representing the co-occurrence matrix with dimensions (len(V), len(V_C)).\n",
    "    \"\"\"\n",
    "    # Initialize the matrix to hold word vectors\n",
    "    C = np.zeros((len(V), len(V_C)), dtype=float)\n",
    "\n",
    "    for line in tqdm(corpus): # Iterate over each word in the original dataset\n",
    "        # Append start and end tokens to the sentence\n",
    "        words = ['<s>'] + line.split(' ') + ['</s>']\n",
    "        length = len(words)\n",
    "\n",
    "        for idx, word in enumerate(words): # Iterate over each word in the current sentence\n",
    "            # Skip '<s>' and '</s>', as they are not real words\n",
    "            if idx > 0 and idx < length - 1 and word in V_set:\n",
    "                # Iterate over left and right context words within the window w\n",
    "                context_words = words[max(idx-w,0):idx] + words[idx+1:min(idx+w+1,length)]\n",
    "\n",
    "                # Constructs a co-occurrence matrix by iterating over context words\n",
    "                # within a specified range and increments counts in the matrix\n",
    "                # for each word-context pair found in a predefined vocabulary.\n",
    "                # It quantifies the relationship between words and their context in a corpus,\n",
    "                # essential for analyzing word associations.\n",
    "\n",
    "                ### BEGIN SOLUTION\n",
    "\n",
    "                for j in range(max(0, idx - w), min(len(words), idx + w + 1)):\n",
    "                    if j != idx and words[j] in V_C_set:\n",
    "                        distance = abs(idx - j)\n",
    "                        weight = 1 / distance if distance > 0 else 1\n",
    "                        C[V_set[word], V_C_set[words[j]]] += weight\n",
    "\n",
    "                ### END SOLUTION\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KAL4m9SDyKA"
   },
   "outputs": [],
   "source": [
    "def eval_word_similarity(C: np.ndarray, V_set: Dict[str, int], path: str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates word similarity by comparing a calculated similarity matrix against a gold standard dataset.\n",
    "\n",
    "    Args:\n",
    "        C (np.ndarray): A 2D NumPy array where rows represent words and columns represent their vector embeddings.\n",
    "        V_set (Dict[str, int]): A dictionary mapping words to their indices in the matrix C.\n",
    "        path (str): The file path to the gold standard dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The Spearman correlation coefficient between the gold standard similarity scores and the calculated scores.\n",
    "    \"\"\"\n",
    "    # Read the gold standard data, skipping the header and the last empty line if present\n",
    "    gold = [line.split('\\t') for line in open(path).read().strip().split('\\n')[1:]]\n",
    "\n",
    "    # Prepare gold scores and similarity scores\n",
    "    y = [float(line[2]) for line in gold]  # Extract gold standard similarity scores\n",
    "    x = [\n",
    "        1 - cosine(C[V_set[word_1], :], C[V_set[word_2], :]) if word_1 in V_set and word_2 in V_set else 0\n",
    "        for word_1, word_2, _ in gold\n",
    "    ]\n",
    "\n",
    "    # Calculate and return Spearman correlation\n",
    "    return stats.spearmanr(x, y, axis=None).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKH1dmT2D8V4",
    "outputId": "cbca5f46-8a0f-4da5-9a89-51835eb1dcf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 997898/997898 [00:48<00:00, 20707.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read the main vocabulary and its indices from a file,\n",
    "# creating a list of words (V) and a dictionary mapping words to indices (V_set).\n",
    "V, V_set = load_vocab_dict('./data/main_words.txt')\n",
    "\n",
    "# Read the context vocabulary and its indices from a separate file,\n",
    "# creating a list of context words (V_C) and a dictionary mapping these words to indices (V_C_set).\n",
    "V_C, V_C_set = load_vocab_dict('./data/context_words.txt')\n",
    "\n",
    "# Read the corpus from a text file, creating a list where each item represents a document or line in the corpus.\n",
    "corpus = read_corpus('./data/corpus.txt')\n",
    "\n",
    "# Generate a co-occurrence (counting) matrix from the corpus using the main and context vocabularies.\n",
    "# The window size 'w=3' indicates the context range around each target word to consider for co-occurrences.\n",
    "C = counting(corpus, V, V_C, V_set, V_C_set, w=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VvhpytXBs1A",
    "outputId": "24707dd3-b3ed-472d-8b03-52fee9edd664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23223229343659896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_word_similarity(C, V_set, './data/men.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNde13fFBxMz",
    "outputId": "f8b94b4c-a48d-4102-9f79-9d398fe9a9bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimmy/venv/lib/python3.11/site-packages/scipy/spatial/distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06530866131712797"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_word_similarity(C, V_set, './data/simlex-999.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAn1zXmOE6zT"
   },
   "outputs": [],
   "source": [
    "def improve_C(C: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Improves the input co-occurrence matrix C using your specified technique.\n",
    "\n",
    "    Args:\n",
    "        C (np.ndarray): The co-occurrence matrix with shape (len(V), len(V_C)), where len(V) is the number of\n",
    "                        vocabulary words, and len(V_C) is the number of context words.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A matrix of shape (len(V), arbitrary_dimension).\n",
    "    \"\"\"\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    total_sum = C.sum()\n",
    "    row_sum = C.sum(axis=1, keepdims=True)\n",
    "    col_sum = C.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    with np.errstate(divide='ignore'):\n",
    "        pmi = np.log2((C * total_sum) / (row_sum @ col_sum))\n",
    "    pmi = np.nan_to_num(pmi, posinf=0, neginf=0)\n",
    "    pmi[pmi < 0] = 0\n",
    "\n",
    "    # Apply SVD for dimensionality reduction to k=100 dimensions\n",
    "    from scipy.sparse.linalg import svds\n",
    "    U, _, _ = svds(pmi, k=100)\n",
    "    return U\n",
    "\n",
    "    ### END SOLUTION\n",
    "\n",
    "C_improved = improve_C(C)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
